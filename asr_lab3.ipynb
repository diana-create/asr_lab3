{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASR Labs 3 and 4 &ndash; Viterbi decoding\n",
    "\n",
    "In these labs we'll use the experience &ndash; and code &ndash; you have developed in previous labs to develop your own Viterbi decoder.  You'll want to refer back to [Lecture 3](http://www.inf.ed.ac.uk/teaching/courses/asr/2019-20/asr03-hmm-algorithms.pdf).  Remember that the Viterbi algorithm is used to find the joint probability of an observation sequence $X$ and the **best** path single path $Q$, allowing this best path to be efficiently discovered. \n",
    "\n",
    "Your decoder will find the best path through the WFST representations HMMs that you developed in Labs 1 and 2.  In the case that your WFST is just a linear chain, the best path will provide an *alignment* of the observation sequence to the HMM states.  If your WFST is a set of word or phone loops (or any other structure) then the best path will allow you to recover the most likely transcription for the observed acoustic features, subject to the constraints of your grammar and vocabulary.\n",
    "\n",
    "Observation probabilities $b_j(t)$ will be supplied for you &ndash; you do not need to use the observations $(x_1, \\dotsc x_T)$ directly.  These are supplied via the `observation_model` module.  You can use this as follows:\n",
    "\n",
    "```python\n",
    "import observation_model as om\n",
    "\n",
    "my_om = om.ObvervationModel()\n",
    "\n",
    "# in future:\n",
    "my_om.load_audio('filename.wav')  \n",
    "\n",
    "# but for now:\n",
    "my_om.load_dummy_audio()  # will generate dummy observations as seen in Lab 2, \n",
    "                          # useful for testing\n",
    "    \n",
    "my_om.observation_length()  # returns the sequence, T  \n",
    "\n",
    "my_om.log_observation_probability(hmm_label, t)  # returns log b_j(t) given HMM label in string form\n",
    "                                                 # raises IndexError if t > T\n",
    "                                                 # raises KeyError if hmm_label is not known\n",
    "```\n",
    "\n",
    "\n",
    "It's easiest to write your decoder as a Python class, and we will supply a template below.  Of course, feel free to use your own structure if you prefer.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'observation_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3d933ab30f72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mobservation_model\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mMyViterbiDecoder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_file_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'observation_model'"
     ]
    }
   ],
   "source": [
    "import observation_model as om\n",
    "\n",
    "class MyViterbiDecoder:\n",
    "    \n",
    "    NLL_ZERO = 1e10  # define a constant representing -log(0).  This is really infinite, but approximate\n",
    "                     # it here with a very large number\n",
    "    \n",
    "    def __init__(self, f, audio_file_name):\n",
    "        \"\"\"Set up the decoder class with an audio file and WFST f\n",
    "        \"\"\"\n",
    "        self.om = observation_model.ObservationModel()\n",
    "        self.f = f\n",
    "        \n",
    "        if audio_file_name:\n",
    "            self.om.load_audio(audio_file_name)\n",
    "        else:\n",
    "            self.om.load_dummy_audio()\n",
    "        \n",
    "        self.initialise_decoding()\n",
    "    \n",
    "    def initialise_decoding(self):\n",
    "        \"\"\"set up the values for V_j(0) (as negative log-likelihoods)\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.V = []\n",
    "        for t in range(self.om.observation_length()+1):\n",
    "            self.V.append([self.NLL_ZERO]*self.f.num_states())\n",
    "        \n",
    "        # The above code means that self.V[t][j] for t = 0, ... T gives the Viterbi cost\n",
    "        # of state j, time t (in negative log-likelihood form)\n",
    "        # Initialising the costs to NLL_ZERO effectively means zero probability    \n",
    "        \n",
    "        # give the WFST start state a probability of 1.0   (NLL = 0.0)\n",
    "        self.f[0][f.start()] = 0.0\n",
    "        \n",
    "        # some WFSTs might have arcs with epsilon on the input (you might have already created \n",
    "        # examples of these in earlier labs) these correspond to non-emitting states, \n",
    "        # which means that we need to process them without stepping forward in time.  \n",
    "        # Don't worry too much about this!  \n",
    "        self.traverse_epsilon_arcs(0)\n",
    "        \n",
    "    def traverse_epsilon_arcs(self, t):\n",
    "        \"\"\"Traverse arcs with <eps> on the input at time t\n",
    "        \n",
    "        These correspond to transitions that don't emit an observation\n",
    "        \n",
    "        We've implemented this function for you as it's slightly trickier than\n",
    "        the normal case.  You might like to look at it to see what's going on, but\n",
    "        don't worry if you can't fully follow it.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        states_to_traverse = range(f.num_states()) # traverse all states\n",
    "        while states_to_traverse:\n",
    "            \n",
    "            # Set i to the ID of the current state, the first \n",
    "            # item in the list (and remove it from the list)\n",
    "            i = states_to_traverse.pop(0)   \n",
    "        \n",
    "            # don't bother traversing states which have zero probability\n",
    "            if V[t][i] == self.NLL_ZERO:\n",
    "                    continue\n",
    "        \n",
    "            for arc in f.arcs(i):\n",
    "                \n",
    "                if arc.ilabel == 0:     # if <eps> transition\n",
    "                  \n",
    "                    j = arc.nextstate   # ID of next state  \n",
    "                \n",
    "                    if V[t][j] > V[t][i] + float(a.weight):\n",
    "                        \n",
    "                        # this means we've found a lower-cost path to\n",
    "                        # state j at time t.  We might need to add it\n",
    "                        # back to the processing queue.\n",
    "                        V[t][j] = V[t][i] + float(a.weight)\n",
    "                  \n",
    "                        if j not in states_to_traverse:\n",
    "                            states_to_traverse.append(j)\n",
    "\n",
    "    \n",
    "    def forward_step(t):\n",
    "        \n",
    "        # TODO - exercise\n",
    "        pass\n",
    "    \n",
    "    def finalise_decoding(self):\n",
    "        \n",
    "        # TODO - exercise\n",
    "        pass\n",
    "    \n",
    "    def decode(self):\n",
    "        \n",
    "        self.initialise_decoding()\n",
    "        t = 1\n",
    "        while t <= self.om.observation_length():\n",
    "            self.forward_step(t)\n",
    "        \n",
    "        self.finalise_decoding()\n",
    "    \n",
    "    def backtrace(self):\n",
    "        \n",
    "        # TODO - exercise \n",
    "        \n",
    "        # complete code to trace back through the\n",
    "        #Â best state sequence\n",
    "        \n",
    "        # You'll need to create a structure B_j(t) to store the \n",
    "        # back-pointers (see lectures), and amend the functions above to fill it.\n",
    "        best_state_sequence = []\n",
    "        return best_state_sequence\n",
    "        \n",
    "\n",
    "# to call the decoder (in a dummy example)\n",
    "# f will be a WFST that you have created in a previous lab\n",
    "decoder = MyViterbiDecoder(f, '')   # empty string '' just means use dummy probabilities for testing\n",
    "decoder.decode()\n",
    "print(decoder.backtrace())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "The `__init__()`, `initialise_decoding()` and `decode()` functions have been completed in the template above.\n",
    "You should aim to complete the `forward_step()` and `finalise_decoding()` functions for Lab 3.  Don't worry about the implementing the back-trace in Lab 3.\n",
    "\n",
    "You should draw on your solutions to Lab 2 &ndash; the main difference now is that, rather than simply sampling a single path and computing its likelihood, you'll need to compute and store, at every time step $t$, and for every state in the WFST, the likelihood of the best path reaching that state after $t$ time steps.  For how to do this using the Viterbi algorithm, see Lecture 3, slides 16 onwards.\n",
    "\n",
    "Test your algorithms on an WFST that recognises the word \"*pepper*\" and one that recognises any word in the vocabulary.\n",
    "\n",
    "## If you have more time\n",
    "\n",
    "You might want to start thinking about how to implementing back-trace to recover your decoder's best path.   Lab 4 will focus on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
